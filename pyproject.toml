[build-system]
requires = ["setuptools>=45", "setuptools_scm[toml]>=6.2"]
build-backend = "setuptools.build_meta"

[project]
name = "outlines"
authors= [{name = "Outlines Developers"}]
description = "Probabilistic Generative Model Programming"
requires-python = ">=3.9,<3.13"
license = {text = "Apache-2.0"}
keywords=[
    "machine learning",
    "deep learning",
    "language models",
    "structured generation",
]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Intended Audience :: Information Technology",
    "Intended Audience :: Science/Research",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
   "interegular",
   "jinja2",
   "lark",
   "nest_asyncio",
   "cloudpickle",
   "diskcache",
   "pydantic>=2.0",
   "referencing",
   "jsonschema",
   "requests",
   "pillow",
   "tqdm",
   "typing_extensions",
   "iso3166",
   "airportsdata",
   "outlines_core==0.1.26",
   "genson",
   "torch",
]
dynamic = ["version"]

[project.optional-dependencies]
anthropic = ["anthropic"]
dottxt = ["dottxt"]
gemini = ["google-genai"]
llamacpp = ["huggingface-hub", "llama-cpp-python"]
mlxlm = ["datasets", "mlx", "mlx-lm"]
ollama = ["ollama"]
openai = ["openai"]
sglang = ["openai"]
tgi = ["huggingface_hub"]
transformers = ["accelerate", "datasets", "transformers"]
vllm = ["openai"]
test = [
    "pre-commit",
    "pytest",
    "pytest-benchmark",
    "pytest-cov",
    "pytest-mock",
    "pytest-asyncio",
    "coverage[toml]>=5.1",
    "diff-cover",
    "accelerate",
    "beartype<0.16.0",
    "responses",
    "llama-cpp-python",
    "mlx-lm>=0.19.2; platform_machine == 'arm64' and sys_platform == 'darwin'",
    "huggingface_hub",
    "openai>=1.0.0",
    "datasets",
    "anthropic",
    "google-genai",
    "transformers<=4.52.1",
    "pillow",
    "jax",
    "flax",
    "numpy>=2.0.0,<2.2.0",
    "torch",
    "tensorflow",
    "tf-keras",
    "ollama",
    "dottxt",
    "sentencepiece",
    "mkdocs_gen_files",
]
test-gpu=["outlines[test]", "vllm; sys_platform == 'linux'"]

[project.urls]
homepage = "https://github.com/dottxt-ai/outlines"
documentation = "https://dottxt-ai.github.io/outlines/"
repository = "https://github.com/dottxt-ai/outlines"

[project.readme]
file="README.md"
content-type = "text/markdown"

[tool.setuptools]
packages = ["outlines"]

[tool.setuptools.package-data]
"outlines" = ["py.typed"]

[tool.setuptools_scm]
write_to = "outlines/_version.py"

[tool.pytest.ini_options]
testpaths = ["tests"]
filterwarnings = [
    "error",
    "ignore::pydantic.warnings.PydanticDeprecatedSince20",
    "ignore::FutureWarning:transformers.*",
    "ignore::FutureWarning:huggingface_hub.*",
    "ignore::UserWarning",
    "ignore::DeprecationWarning:pyairports.*",
    "ignore::DeprecationWarning:jax.*",
    "ignore::DeprecationWarning:flax.*",
]

[tool.mypy]
exclude=["examples"]
enable_incomplete_feature = ["Unpack"]

[[tool.mypy.overrides]]
module = [
    "jax",
    "jaxlib",
    "jax.numpy",
    "jinja2",
    "jsonschema.*",
    "anthropic.*",
    "google.*",
    "mamba_ssm.*",
    "mlx_lm.*",
    "mlx.*",
    "nest_asyncio",
    "numpy.*",
    "cloudpickle.*",
    "diskcache.*",
    "pydantic.*",
    "pydantic_core.*",
    "pytest",
    "referencing.*",
    "torch.*",
    "transformers.*",
    "llama_cpp",
    "huggingface_hub",
    "lark.*",
    "interegular.*",
    "datasets.*",
    "openai.*",
    "requests.*",
    "responses.*",
    "vllm.*",
    "iso3166.*",
    "airportsdata.*",
    "outlines_core.*",
    "genson",
    "ollama.*",
    "dottxt.*",
    "tensorflow",
    "tensorflow.*",
    "tf-keras",
    "tf-keras.*",
    "mkdocs_gen_files.*",
]
ignore_missing_imports = true

[tool.coverage.run]
# we omit the files that require a GPU or Apple Silicon
# as well as the models that make API calls
omit = [
    "outlines/_version.py",
    "outlines/models/anthropic.py",
    "outlines/models/dottxt.py",
    "outlines/models/gemini.py",
    "outlines/models/mlxlm.py",
    "outlines/models/openai.py",
    "outlines/models/vllm_offline.py",
    "outlines/processors/tensor_adapters/mlx.py",
    "outlines/v0_legacy/models/anthropic.py",
    "outlines/v0_legacy/models/dottxt.py",
    "outlines/v0_legacy/models/exllamav2.py",
    "outlines/v0_legacy/models/gemini.py",
    "outlines/v0_legacy/models/mlxlm.py",
    "outlines/v0_legacy/models/openai.py",
    "outlines/v0_legacy/models/vllm_offline.py",
    "tests/*",
]
branch = true
relative_files = true

[tool.coverage.report]
show_missing = true
exclude_lines = [
    "pragma: no cover",
    "if TYPE_CHECKING:",
    "\\.\\.\\.",
]

[tool.diff_cover]
compare_branch = "origin/main"
diff_range_notation = ".."

[tool.docformatter]
style = "numpy"
in-place = true

[tool.ruff.lint]
ignore = [ "E731", "F401" ]
